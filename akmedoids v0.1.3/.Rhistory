carperc[is.na(carperc)] <- 0
homeperc[is.na(homeperc)] <- 0
lnoverperc<-(log(overperc+1))
lnunempperc<-(log(unempperc+1))
zcar<-((carperc-mean(carperc))/sd(carperc))
zhome<-((homeperc-mean(homeperc))/sd(homeperc))
zover<-((lnoverperc-mean(lnoverperc))/sd(lnoverperc))
zunemp<-((lnunempperc-mean(lnunempperc))/sd(lnunempperc))
TDS<- (zcar + zhome + zover + zunemp)
ukdata_$TDS<-TDS
quintile <- cut(TDS, quantile(TDS, probs=0:n_classes/n_classes, na.rm=TRUE), include.lowest=TRUE, labels=FALSE)
#quintile <- cut(TDS, quantile(TDS, probs=0:n_classes/n_classes, na.rm=TRUE), include.lowest=TRUE, labels=FALSE)
Townsendscores<-data.frame(ukdata_$GEO_CODE, ukdata_$GEO_LABEL, ukdata_$TDS, quintile)
names(Townsendscores)[names(Townsendscores) == "ukdata_.GEO_CODE"]<-"geo_code"
names(Townsendscores)[names(Townsendscores) == "ukdata_.GEO_LABEL"]<-"geo_label"
names(Townsendscores)[names(Townsendscores) == "ukdata_.TDS"]<-"TDS"
#write.csv(Townsendscores, "insertfilename.csv")
#write.table(Townsendscores, file="england_TSD_2011.csv", sep=",", row.names = F)
head(Townsendscores) #nrow(Townsendscores)
return(Townsendscores)
#------------------------------------------------------------------
}
tsd <- tsd_ind_(code = uni_codes, unit = "LSOA", n_classes = 5)
traceback()
tsd_ind_ <- function(code = code, unit = "LSOA", n_classes = 10){  #getwd()
wd = "C:/Users/monsu/Documents/GitHub/Packages/inter_comparison_Micro/"
#import the 2011 data
if(unit == "LSOA"|unit == "DZ"){
ukdata_ <- read.csv(file=paste(wd, "Dataset- 2011 UK LSOA.csv", sep=""), sep=",", head=TRUE) #head(ukdata_)  #nrow(ukdata_)
}
if(unit == "OA"|unit == "Output Area"){
ukdata_ <- read.csv(file="Dataset- 2011 UK Output Area.csv", sep=",", head=TRUE) #head(ukdata_)  #nrow(ukdata_)
}
#crop the england uk
ukdata_ <- ukdata_[which(ukdata_$GEO_CODE %in% code), ] #nrow(ukdata_)#head(ukdata_)
carperc<-((ukdata_$F991/ukdata_$F989)*100)
homeperc<-(((ukdata_$F2357+ukdata_$F2362+ukdata_$F2368)/ukdata_$F2347)*100)
overperc<-(((ukdata_$F2081+ukdata_$F2083)/ukdata_$F2075)*100)
unempperc<-((ukdata_$F248/ukdata_$F244)*100)
overperc[is.na(overperc)] <- 0
unempperc[is.na(unempperc)] <- 0
carperc[is.na(carperc)] <- 0
homeperc[is.na(homeperc)] <- 0
lnoverperc<-(log(overperc+1))
lnunempperc<-(log(unempperc+1))
zcar<-((carperc-mean(carperc))/sd(carperc))
zhome<-((homeperc-mean(homeperc))/sd(homeperc))
zover<-((lnoverperc-mean(lnoverperc))/sd(lnoverperc))
zunemp<-((lnunempperc-mean(lnunempperc))/sd(lnunempperc))
TDS<- (zcar + zhome + zover + zunemp)
ukdata_$TDS<-TDS
quintile <- cut(TDS, quantile(TDS, probs=0:n_classes/n_classes, na.rm=TRUE), include.lowest=TRUE, labels=FALSE)
#quintile <- cut(TDS, quantile(TDS, probs=0:n_classes/n_classes, na.rm=TRUE), include.lowest=TRUE, labels=FALSE)
Townsendscores<-data.frame(ukdata_$GEO_CODE, ukdata_$GEO_LABEL, ukdata_$TDS, quintile)
names(Townsendscores)[names(Townsendscores) == "ukdata_.GEO_CODE"]<-"geo_code"
names(Townsendscores)[names(Townsendscores) == "ukdata_.GEO_LABEL"]<-"geo_label"
names(Townsendscores)[names(Townsendscores) == "ukdata_.TDS"]<-"TDS"
#write.csv(Townsendscores, "insertfilename.csv")
#write.table(Townsendscores, file="england_TSD_2011.csv", sep=",", row.names = F)
head(Townsendscores) #nrow(Townsendscores)
return(Townsendscores)
#------------------------------------------------------------------
}
tsd <- tsd_ind_(code = uni_codes, unit = "LSOA", n_classes = 5)
head(tsd)
nrow(tsd)
clustr
part2 <- clustr
#grp_ <- list(c(1:3), c(4:6), c(7:9)) #for b LSOA##repeat no removal but 3,3,3  ...223 remove
grp_ <- list(c(1:3), c(4:6), c(7:9)) #no removal
colours <- c(rep("#00FF00", 3), rep("yellow",3), rep("red", 3)) #bm....LSOA
geo_unique
head(prop_crime_per000_people)
#rownames(data.append) <- 1:nrow(data.append)
data.append <- cbind(1:nrow(prop_crime_per000_people),
prop_crime_per000_people[,2:ncol(prop_crime_per000_people)]) #
head(data.append) #data.append <- data  #data <-
colnames(data.append) <- c("code", 1:length(2002:year_to))
data.append <- as.data.frame(data.append)  #
head(data.append)
year_to <- 2016
colnames(data.append) <- c("code", 1:length(2002:year_to))
data.append <- as.data.frame(data.append)  #
head(data.append)
data.long.melted <- melt(data.append, id="code")#head(data., id="code"
head(data.long.melted)
library(reshape2)
data.long.melted <- melt(data.append, id="code")#head(data., id="code"
head(data.long.melted)
#data.append <- cbind(data, part2)
#data.long.melted <- melt(data, id="code")#head(d
data.long.melted <- cbind(data.long.melted, rep(part2, length(2002:year_to)))#head(data.long.melted)
colnames(data.long.melted) <- c("OAcode","Year","Crime_Count", "clusters")
head(data.long.melted)##data.long.melted[1:50,]
#use this to calculate percentage (%) change from year 1 to year n
year_uni <- as.vector(unique(data.long.melted$Year))
order_Cluster <- as.vector(unique(data.long.melted$clusters))
clusters_uni <- order_Cluster[order(as.vector(unique(data.long.melted$clusters)))]
change_ave_yr <- NULL
for(p in 1:length(clusters_uni)){#p<-1
all_clust_list <- data.long.melted[which(data.long.melted$clusters==clusters_uni[p]),]
ave_yr <- NULL
for(m in 1:length(year_uni)){ #m<-1
yr_ <- all_clust_list[which(as.vector(all_clust_list$Year)==year_uni[m]),]#all first year data..
ave_yr <- c(ave_yr, sum(yr_$Crime_Count))
}
change_ave_yr <- c(change_ave_yr, round(((ave_yr[length(ave_yr)]-ave_yr[1])/ave_yr[1])*100, digits=0))
}
change_ave_yr  <- list(change_ave_yr)
flush.console()
print(change_ave_yr)
head(data.long.melted)##data.long.melted[1:50,]
change_ave_yr_ALL <- NULL
for(p in 1:length(clusters_uni)){#p<-1
all_clust_list <- data.long.melted[which(data.long.melted$clusters==clusters_uni[p]),]
ave_yr <- NULL
for(m in 1:length(year_uni)){ #m<-1
yr_ <- all_clust_list[which(as.vector(all_clust_list$Year)==year_uni[m]),]#all first year data..
ave_yr <- c(ave_yr, sum(yr_$Crime_Count))
}
change_ave_yr_ALL <- rbind(change_ave_yr_ALL,  ave_yr)
}
change_ave_yr_ALL  #USE THIS FOR THE DESCRIPTIVE COMPUTATION
change_ave_yr_ALL <- t(change_ave_yr_ALL)
#re-arrange gl2_ violent
change_ave_yr_ALL <-  change_ave_yr_ALL[,unlist(grp_)]
#create data frame for use with plot
#grp.dat<-matrix(grp.dat,nrow=length(t.step),ncol=length(grps))
grp.dat<-data.frame(change_ave_yr_ALL,row.names=1:length(2002:year_to))
names(grp.dat)<-clusters_uni
#reshape the data
p.dat<-data.frame(step=row.names(grp.dat),grp.dat,stringsAsFactors=F) #p.dat
p.dat<-melt(p.dat,id='step')
p.dat$step<-as.numeric(p.dat$step) #head(p.dat)
class(p.dat$step)
colfunc <- colorRampPalette(c("green", "yellow", "red"))
Year <- as.character(c(2002:year_to))
p <- ggplot(p.dat,aes(x=step,y=value)) + theme(legend.position="none")  #grp_
library(ggplots)
library(ggplot)
library(ggplot2)
p <- ggplot(p.dat,aes(x=step,y=value)) + theme(legend.position="none")  #grp_
p + geom_area(aes(fill=variable), colour = "gray5", position='fill', size = 0.5) +
scale_fill_manual(values = colours) +
scale_x_continuous(breaks=1:length(Year), labels=Year) + theme_light()
part2
clusters <- part2
#calculate the cumulative rate of change (first difference) of the mean value ......data.long.melted
clusters <- clusters[1:nrow(prop_crime_per000_people)]
data_reMelt <- dcast(data.long.melted, OAcode ~ Year, value.var='Crime_Count')  #data_reMelt[1:10,]
data_reMelt <- cbind(data_reMelt, clusters) #head(data_reMelt)
cluster_Group <- as.vector(unique(data_reMelt$clusters)[order(unique(data_reMelt$clusters))])
length_Of_Clusters <- NULL
cluster_Units_ALL <- list()
for(i in 1:length(cluster_Group)){ #i<-1
data_reMelt_Cut <- data_backup[which(data_reMelt$clusters==cluster_Group[i]),]#head(data_reMelt)
if(is.null(data_reMelt_Cut)){data_reMelt_Cut<-matrix(data_reMelt_Cut,,(length(Year)+1))
colnames(data_reMelt_Cut) <- c("code", as.character(1:length(Year)))
}
#get the corresponding OA label #head(data)# head(agg_Data[1:10,])
cluster_Units <- as.vector(agg_Data$V1[as.data.frame(data_reMelt_Cut)$ID])
length_Of_Clusters <- rbind(length_Of_Clusters, cbind(i, length(cluster_Units)))
cluster_Units_ALL[i] <- list(cluster_Units)
}
sp::plot(WM_LSOA, col="grey", border="grey", pch=16)
WM_LSOA <- readOGR(dsn=".", paste(study_Area, "LSOA_hex", sep="")) #geo_unit_with_POPData   #getwd()
setwd("C:/Users/monsu/Documents/UNI DESKTOP BACKUP _13062019/desktop/FoSS Slides_/")
WM_LSOA <- readOGR(dsn=".", paste(study_Area, "LSOA_hex", sep="")) #geo_unit_with_POPData   #getwd()
#not sure for glasgow
##grp_ <- list(c(1:3), c(4:6), c(7:9)) #for b
##colours <- c(rep("#00FF00", 2), rep("yellow", 2), rep("red", 2)) #violenct
library(rgdal)
setwd("C:/Users/monsu/Documents/UNI DESKTOP BACKUP _13062019/desktop/FoSS Slides_/")
WM_LSOA <- readOGR(dsn=".", paste(study_Area, "LSOA_hex", sep="")) #geo_unit_with_POPData   #getwd()
sp::plot(WM_LSOA, col="grey", border="grey", pch=16)
#plotting for gradient colour#dev.new()
#--------------------------------------------
cc_ <- 0
countt_ <- 0
#spatial patterning
for(q in 1:length(grp_)){ #q<-3
#for(p in 1:length(cluster_Units_ALL)){
#combine
colat_<- NULL
for(f in 1:length(grp_[[q]])){ # f<-1
cc_ <- cc_ + 1
##colat_ <- c(colat_, cluster_Units_ALL[[grp_[[q]][f]]])
colat_ <- cluster_Units_ALL[[grp_[[q]][f]]]
print(length(cluster_Units_ALL[[grp_[[q]][f]]]))
#}
sp::plot(WM_LSOA[which(as.vector(WM_LSOA$code)%in%colat_),], add=TRUE, col=colours[cc_], border="grey50", pch=16) #check that OA field is correct
}
#countt_ <- countt_ + length(unlist(grp_[c(q)]))
}
agg_Data <- as.data.frame(cbind(V1=crime_per_000_people$code, crime_per_000_people[,2:ncol(crime_per_000_people)]))  #head(agg_Data)
head(agg_Data)
length_Of_Clusters <- NULL
cluster_Units_ALL <- list()
i<-1
data_reMelt_Cut <- data_backup[which(data_reMelt$clusters==cluster_Group[i]),]#head(data_reMelt)
#workspace setting #------------------------------------------
#study_Area <- "wm_bm_"
study_Area <- "wm_bm_"
crime_type <- "PC_"
data <- read.table("C:/Users/monsu/Documents/GitHub/Packages/inter_comparison_Micro/data1_1/wm_bm_PC_LSOA_.csv", sep=",", head=TRUE)  #head(data) #nrow(data)
head(data)
data <- cbind(data$code, data[,4:ncol(data)])
head(data)
colnames(data) <- c("code", paste("p", 2002:2016, sep=""))
head(data)
#---------------------------------
#read the attribute table of the ESRI data (for 'study_area1'), including the population data
df <- read.dbf(paste("C:/Users/monsu/Documents/GitHub/Packages/v013/data2/shp1/",
study_Area, "LSOA_", "pop_02_12.dbf", sep=""))#head(df) #nrow(df)
others_ <- read.table("C:/Users/monsu/Documents/GitHub/Packages/inter_comparison_Micro/data1_1/WM_MID_YEAR_POP_ESIMATE_2002to2017.csv", sep = ",", head=TRUE)
#head(others_)
uni_codes <- as.vector(df$code)
all_ <- NULL
for(t in 1:length(uni_codes)){#t<-1
id_ <- which(others_$LSOA11CD==uni_codes[t])
sub_ <- others_[id_, 4:ncol(others_)]
all_ <- rbind(all_, sub_)
}
all_ <- cbind(uni_codes, all_)
#row.names(all_) <- uni_codes
colnames(all_) <- c("code", paste("p", 2002:2016, sep="")) #
head(all_)#nrow(all_)
df <- all_
#move the first row
#df <- as.data.frame(cbind(df$code, df[,1:(ncol(df)-1)]))   #df[which(df[,1]=="E01009510"),]
df <- as.data.frame(df)
head(df) #nrow(df) mode(df)
#subset the crime data with LSOA ids
data_sub <- as.data.frame(data[which(data$code %in% as.vector(df[,1])),])  #head(data_sub)  nrow(data_sub) #data[1,] #mode(data_sub)# #library(akmedoids)
#Calculate 'rates' ##==========
crime_per_000_people <- rates(data_sub, denomin=df, id_field=TRUE,
multiplier = 1000)
head(crime_per_000_people)  #nrow(crime_per_000_people)
agg_Data <- as.data.frame(cbind(V1=crime_per_000_people$code, crime_per_000_people[,2:ncol(crime_per_000_people)]))  #head(agg_Data)
head(agg_Data)
prop_crime_per000_people <- props(crime_per_000_people, id_field = TRUE, scale = 1, digits = 4)
head(prop_crime_per000_people) #prop_crime_per000_people[,2]
data_backup <- prop_crime_per000_people
#clustering: 'akmedoids.clust' ##==========
cluster_output <- akmedoids.clust(prop_crime_per000_people, id_field = TRUE,
method = "linear", k = c(3,20))
#retrieve cluster attributes: 'statPrint' ##========
clustr <- as.vector(cluster_output$optimSolution)
#line plot
print(statPrint(clustr, prop_crime_per000_people, id_field=TRUE, reference = 1,
N.quant = 8, type="lines", y.scaling="free"))
#areal plot
print(statPrint(clustr, prop_crime_per000_people, id_field=TRUE, reference = 1,
N.quant = 4, type="stacked"))
#-----------------------------------------
#deprivation data
#read the attribute table of the ESRI data (for 'study_area1'), including the population data
code <- df$code
tsd <- tsd_ind_(code = uni_codes, unit = "LSOA", n_classes = 5)
head(tsd) #nrow(tsd)
year_to <- 2016
part2 <- clustr
#grp_ <- list(c(1:3), c(4:6), c(7:9)) #for b LSOA##repeat no removal but 3,3,3  ...223 remove
grp_ <- list(c(1:3), c(4:6), c(7:9)) #no removal
colours <- c(rep("#00FF00", 3), rep("yellow",3), rep("red", 3)) #bm....LSOA
#rownames(data.append) <- 1:nrow(data.append)
data.append <- cbind(1:nrow(prop_crime_per000_people),
prop_crime_per000_people[,2:ncol(prop_crime_per000_people)]) #
head(data.append) #data.append <- data  #data <-
colnames(data.append) <- c("code", 1:length(2002:year_to))
data.append <- as.data.frame(data.append)  #
head(data.append)
data.long.melted <- melt(data.append, id="code")#head(data., id="code"
head(data.long.melted)
#data.append <- cbind(data, part2)
#data.long.melted <- melt(data, id="code")#head(d
data.long.melted <- cbind(data.long.melted, rep(part2, length(2002:year_to)))#head(data.long.melted)
colnames(data.long.melted) <- c("OAcode","Year","Crime_Count", "clusters")
head(data.long.melted)##data.long.melted[1:50,]
#use this to calculate percentage (%) change from year 1 to year n
year_uni <- as.vector(unique(data.long.melted$Year))
order_Cluster <- as.vector(unique(data.long.melted$clusters))
clusters_uni <- order_Cluster[order(as.vector(unique(data.long.melted$clusters)))]
change_ave_yr <- NULL
for(p in 1:length(clusters_uni)){#p<-1
all_clust_list <- data.long.melted[which(data.long.melted$clusters==clusters_uni[p]),]
ave_yr <- NULL
for(m in 1:length(year_uni)){ #m<-1
yr_ <- all_clust_list[which(as.vector(all_clust_list$Year)==year_uni[m]),]#all first year data..
ave_yr <- c(ave_yr, sum(yr_$Crime_Count))
}
change_ave_yr <- c(change_ave_yr, round(((ave_yr[length(ave_yr)]-ave_yr[1])/ave_yr[1])*100, digits=0))
}
change_ave_yr  <- list(change_ave_yr)
print(change_ave_yr)
head(data.long.melted)##data.long.melted[1:50,]
change_ave_yr_ALL <- NULL
for(p in 1:length(clusters_uni)){#p<-1
all_clust_list <- data.long.melted[which(data.long.melted$clusters==clusters_uni[p]),]
ave_yr <- NULL
for(m in 1:length(year_uni)){ #m<-1
yr_ <- all_clust_list[which(as.vector(all_clust_list$Year)==year_uni[m]),]#all first year data..
ave_yr <- c(ave_yr, sum(yr_$Crime_Count))
}
change_ave_yr_ALL <- rbind(change_ave_yr_ALL,  ave_yr)
}
change_ave_yr_ALL  #USE THIS FOR THE DESCRIPTIVE COMPUTATION
change_ave_yr_ALL <- t(change_ave_yr_ALL)
#re-arrange gl2_ violent
change_ave_yr_ALL <-  change_ave_yr_ALL[,unlist(grp_)]
#create data frame for use with plot
#grp.dat<-matrix(grp.dat,nrow=length(t.step),ncol=length(grps))
grp.dat<-data.frame(change_ave_yr_ALL,row.names=1:length(2002:year_to))
names(grp.dat)<-clusters_uni
#reshape the data
p.dat<-data.frame(step=row.names(grp.dat),grp.dat,stringsAsFactors=F) #p.dat
p.dat<-melt(p.dat,id='step')
p.dat$step<-as.numeric(p.dat$step) #head(p.dat)
class(p.dat$step)
colfunc <- colorRampPalette(c("green", "yellow", "red"))
Year <- as.character(c(2002:year_to))
p <- ggplot(p.dat,aes(x=step,y=value)) + theme(legend.position="none")  #grp_
p + geom_area(aes(fill=variable), colour = "gray5", position='fill', size = 0.5) +
scale_fill_manual(values = colours) +
scale_x_continuous(breaks=1:length(Year), labels=Year) + theme_light()
#removing the sub-grouplines
p + geom_area(aes(fill=variable), colour = 'NA', position='fill', size = 0.5) +
scale_fill_manual(values = colours) +
scale_x_continuous(breaks=1:length(Year), labels=Year) + theme_light()
clusters <- part2
#calculate the cumulative rate of change (first difference) of the mean value ......data.long.melted
clusters <- clusters[1:nrow(prop_crime_per000_people)]
data_reMelt <- dcast(data.long.melted, OAcode ~ Year, value.var='Crime_Count')  #data_reMelt[1:10,]
data_reMelt <- cbind(data_reMelt, clusters) #head(data_reMelt)
cluster_Group <- as.vector(unique(data_reMelt$clusters)[order(unique(data_reMelt$clusters))])
length_Of_Clusters <- NULL
cluster_Units_ALL <- list()
for(i in 1:length(cluster_Group)){ #i<-1
data_reMelt_Cut <- data_backup[which(data_reMelt$clusters==cluster_Group[i]),]#head(data_reMelt)
if(is.null(data_reMelt_Cut)){data_reMelt_Cut<-matrix(data_reMelt_Cut,,(length(Year)+1))
colnames(data_reMelt_Cut) <- c("code", as.character(1:length(Year)))
}
#get the corresponding OA label #head(data)# head(agg_Data[1:10,])
cluster_Units <- as.vector(agg_Data$V1[as.data.frame(data_reMelt_Cut)$ID])
length_Of_Clusters <- rbind(length_Of_Clusters, cbind(i, length(cluster_Units)))
cluster_Units_ALL[i] <- list(cluster_Units)
}
cluster_Units_ALL
cluster_Units
length_Of_Clusters <- NULL
cluster_Units_ALL <- list()
i<-1
cluster_Group[i]
head(data_backup)
head(data_reMelt)
data_reMelt_Cut <- data_backup[which(data_reMelt$clusters==cluster_Group[i]),]#head(data_backup) #head(data_reMelt)
head(data_reMelt_Cut)
if(is.null(data_reMelt_Cut)){data_reMelt_Cut<-matrix(data_reMelt_Cut,,(length(Year)+1))
colnames(data_reMelt_Cut) <- c("code", as.character(1:length(Year)))
}
head(data_reMelt_Cut)
head(data_reMelt_Cut)
head(data_backup)
length_Of_Clusters <- NULL
cluster_Units_ALL <- list()
for(i in 1:length(cluster_Group)){ #i<-1
data_reMelt_Cut <- data_backup[which(data_reMelt$clusters==cluster_Group[i]),]#head(data_backup) #head(data_reMelt) #head(data_reMelt_Cut)
if(is.null(data_reMelt_Cut)){data_reMelt_Cut<-matrix(data_reMelt_Cut,,(length(Year)+1))
colnames(data_reMelt_Cut) <- c("code", as.character(1:length(Year)))
}
#get the corresponding OA label #head(data)# head(agg_Data[1:10,])
cluster_Units <- as.vector(agg_Data$V1[as.data.frame(data_reMelt_Cut)$code])
length_Of_Clusters <- rbind(length_Of_Clusters, cbind(i, length(cluster_Units)))
cluster_Units_ALL[i] <- list(cluster_Units)
}
cluster_Units_ALL
#study_Area <- "gl_"
study_Area <- "gl2_"
#read the geographical shapefile and population data
geo_unit_with_POPData <- readOGR(dsn=".", paste(study_Area, "LSOA_", "pop_02_12", sep=""))
head(geo_unit_with_POPData@data) #nrow(geo_unit_with_POPData@data)
geo_unit_with_POPData[geo_unit_with_POPData$code=="S01010273",]
getwd()
geo_unit_with_POPData[geo_unit_with_POPData$code=="S01010272",]
cluster_Units_ALL
sp::plot(WM_LSOA, col="grey", border="grey", pch=16)
#plotting for gradient colour#dev.new()
#--------------------------------------------
cc_ <- 0
countt_ <- 0
#spatial patterning
for(q in 1:length(grp_)){ #q<-3
#for(p in 1:length(cluster_Units_ALL)){
#combine
colat_<- NULL
for(f in 1:length(grp_[[q]])){ # f<-1
cc_ <- cc_ + 1
##colat_ <- c(colat_, cluster_Units_ALL[[grp_[[q]][f]]])
colat_ <- cluster_Units_ALL[[grp_[[q]][f]]]
print(length(cluster_Units_ALL[[grp_[[q]][f]]]))
#}
sp::plot(WM_LSOA[which(as.vector(WM_LSOA$code)%in%colat_),], add=TRUE, col=colours[cc_], border="grey50", pch=16) #check that OA field is correct
}
#countt_ <- countt_ + length(unlist(grp_[c(q)]))
}
sp::plot(city_Centre, col="NA", border="black", pch=16, add=TRUE, lwd=3)
#---------------------------------------------------
import_map_ <- readOGR(dsn=".", paste(study_Area, "LSOA_hex", sep="")) #geo_unit_with_POPData
import_map_ <- import_map_@data
head(import_map_)
unit
unit=
"LSOA"
#---------------------------------------------------
import_map_ <- readOGR(dsn=".", paste(study_Area, "LSOA_hex", sep="")) #geo_unit_with_POPData
import_map_ <- import_map_@data
head(import_map_)
#workspace setting #------------------------------------------
#study_Area <- "wm_bm_"
study_Area <- "wm_bm_"
crime_type <- "PC_"
part2 <- clustr
#grp_ <- list(c(1:3), c(4:6), c(7:9)) #for b LSOA##repeat no removal but 3,3,3  ...223 remove
grp_ <- list(c(1:3), c(4:6), c(7:9)) #no removal
colours <- c(rep("#00FF00", 3), rep("yellow",3), rep("red", 3)) #bm....LSOA
WM_LSOA <- readOGR(dsn=".", paste(study_Area, "LSOA_hex", sep="")) #geo_unit_with_POPData   #getwd()
sp::plot(WM_LSOA, col="grey", border="grey", pch=16)
WM_LSOA
length(WM_LSOA)
#plotting for gradient colour#dev.new()
#--------------------------------------------
cc_ <- 0
countt_ <- 0
#spatial patterning
for(q in 1:length(grp_)){ #q<-3
#for(p in 1:length(cluster_Units_ALL)){
#combine
colat_<- NULL
for(f in 1:length(grp_[[q]])){ # f<-1
cc_ <- cc_ + 1
##colat_ <- c(colat_, cluster_Units_ALL[[grp_[[q]][f]]])
colat_ <- cluster_Units_ALL[[grp_[[q]][f]]]
print(length(cluster_Units_ALL[[grp_[[q]][f]]]))
#}
sp::plot(WM_LSOA[which(as.vector(WM_LSOA$code)%in%colat_),], add=TRUE, col=colours[cc_], border="grey50", pch=16) #check that OA field is correct
}
#countt_ <- countt_ + length(unlist(grp_[c(q)]))
}
sp::plot(city_Centre, col="NA", border="black", pch=16, add=TRUE, lwd=3)
nrow(geo_unit_with_POPData@data)
head(geo_unit_with_POPData@data) #nrow(geo_unit_with_POPData@data) #getwd()
getwd()
#workspace setting #------------------------------------------
#study_Area <- "wm_bm_"
study_Area <- "wm_bm_"
crime_type <- "PC_"
data <- read.table("C:/Users/monsu/Documents/GitHub/Packages/inter_comparison_Micro/data1_1/wm_bm_PC_LSOA_.csv", sep=",", head=TRUE)  #head(data) #nrow(data)
head(data)
data <- cbind(data$code, data[,4:ncol(data)])
head(data)
colnames(data) <- c("code", paste("p", 2002:2016, sep=""))
head(data)
#---------------------------------
#read the attribute table of the ESRI data (for 'study_area1'), including the population data
df <- read.dbf(paste("C:/Users/monsu/Documents/GitHub/Packages/v013/data2/shp1/",
study_Area, "LSOA_", "pop_02_12.dbf", sep=""))#head(df) #nrow(df)
others_ <- read.table("C:/Users/monsu/Documents/GitHub/Packages/inter_comparison_Micro/data1_1/WM_MID_YEAR_POP_ESIMATE_2002to2017.csv", sep = ",", head=TRUE)
#head(others_)
uni_codes <- as.vector(df$code)
all_ <- NULL
library(foreign)
#---------------------------------
#read the attribute table of the ESRI data (for 'study_area1'), including the population data
df <- read.dbf(paste("C:/Users/monsu/Documents/GitHub/Packages/v013/data2/shp1/",
study_Area, "LSOA_", "pop_02_12.dbf", sep=""))#head(df) #nrow(df)
others_ <- read.table("C:/Users/monsu/Documents/GitHub/Packages/inter_comparison_Micro/data1_1/WM_MID_YEAR_POP_ESIMATE_2002to2017.csv", sep = ",", head=TRUE)
#head(others_)
uni_codes <- as.vector(df$code)
all_ <- NULL
for(t in 1:length(uni_codes)){#t<-1
id_ <- which(others_$LSOA11CD==uni_codes[t])
sub_ <- others_[id_, 4:ncol(others_)]
all_ <- rbind(all_, sub_)
}
all_ <- cbind(uni_codes, all_)
#row.names(all_) <- uni_codes
colnames(all_) <- c("code", paste("p", 2002:2016, sep="")) #
head(all_)#nrow(all_)
df <- all_
#move the first row
#df <- as.data.frame(cbind(df$code, df[,1:(ncol(df)-1)]))   #df[which(df[,1]=="E01009510"),]
df <- as.data.frame(df)
head(df) #nrow(df) mode(df)
#subset the crime data with LSOA ids
data_sub <- as.data.frame(data[which(data$code %in% as.vector(df[,1])),])  #head(data_sub)  nrow(data_sub) #data[1,] #mode(data_sub)# #library(akmedoids)
#Calculate 'rates' ##==========
crime_per_000_people <- rates(data_sub, denomin=df, id_field=TRUE,
multiplier = 1000)
head(crime_per_000_people)  #nrow(crime_per_000_people)
agg_Data <- as.data.frame(cbind(V1=crime_per_000_people$code, crime_per_000_people[,2:ncol(crime_per_000_people)]))  #head(agg_Data)
getwd()
install.packages("roxygen2")
library(roxygens)
library(roxygens2)
library(roxygen2)
#workspace setting #------------------------------------------
#study_Area <- "wm_bm_"
study_Area <- "wm_bm_"
crime_type <- "PC_"
install.packages("kml")
library(kml)
library(foreign)
